[0m[[0m[0mdebug[0m] [0m[0m> Exec(run, Some(32baea41-7cf1-4044-bc3f-00ab110410a0), Some(CommandSource(console0)))[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / run[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 1 Scala source to C:\Users\Khoa\Desktop\CensusData\target\scala-2.11\classes ...[0m
[0m[[0m[0mdebug[0m] [0m[0mForcing garbage collection...[0m
[0m[[0m[31merror[0m] [0m[0mjava.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2154)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2580)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2593)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2632)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2614)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:709)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:390)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:390)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.flatMap(List.scala:355)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:389)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:622)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:606)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery$.main(SQLquery.scala:30)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery.main(SQLquery.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.reflect.Method.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:186)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0mCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2060)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2152)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2580)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2593)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2632)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2614)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:709)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:390)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:390)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.flatMap(List.scala:355)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:389)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:622)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:606)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery$.main(SQLquery.scala:30)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery.main(SQLquery.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.reflect.Method.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:186)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 6 s, completed Aug 17, 2022 12:23:37 PM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
