[0m[[0m[31merror[0m] [0m[0morg.apache.spark.sql.AnalysisException: cannot resolve '`2010`' given input columns: [s0.state, s1.state, s1.regionID, s0.Hispanic_Latino, s1.African, s0.NativeHawaiian_PacificIslander, s0.stateID, s0.Asian, s1.totalPop, s0.regionID, s2.state, s2.African, s2.White, s1.stateID, s1.Hispanic_Latino, s2.OtherRace, s1.Asian, s0.OtherRace, s1.NativeHawaiian_PacificIslander, s0.totalPop, s2.stateID, s0.Indian, s0.African, s2.totalPop, s2.Hispanic_Latino, s1.White, s0.White, s1.OtherRace, s1.Indian, s2.Indian, s2.regionID, s2.NativeHawaiian_PacificIslander, s2.Asian]; line 1 pos 107;[0m
[0m[[0m[31merror[0m] [0m[0m'GlobalLimit 5[0m
[0m[[0m[31merror[0m] [0m[0m+- 'LocalLimit 5[0m
[0m[[0m[31merror[0m] [0m[0m   +- 'Sort ['diffence2 DESC NULLS LAST], true[0m
[0m[[0m[31merror[0m] [0m[0m      +- 'Project [state#98, totalPop#99 AS 2000#162, totalPop#121 AS 2010#163, (cast(totalPop#121 as double) - cast(totalPop#99 as double)) AS diffence#164, '2010, totalPop#143 AS 2020#165, (cast(totalPop#143 as double) - cast(totalPop#121 as double)) AS diffence2#166][0m
[0m[[0m[31merror[0m] [0m[0m         +- Join Inner, (stateID#140 = stateID#118)[0m
[0m[[0m[31merror[0m] [0m[0m            :- Join Inner, (stateID#118 = stateID#96)[0m
[0m[[0m[31merror[0m] [0m[0m            :  :- SubqueryAlias s0[0m
[0m[[0m[31merror[0m] [0m[0m            :  :  +- SubqueryAlias states00[0m
[0m[[0m[31merror[0m] [0m[0m            :  :     +- Project [_c0#10 AS stateID#96, _c1#11 AS regionID#97, _c2#12 AS state#98, _c3#13 AS totalPop#99, _c4#14 AS White#100, _c5#15 AS African#101, _c6#16 AS Indian#102, _c7#17 AS Asian#103, _c8#18 AS NativeHawaiian_PacificIslander#104, _c9#19 AS OtherRace#105, _c10#20 AS Hispanic_Latino#106][0m
[0m[[0m[31merror[0m] [0m[0m            :  :        +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20] csv[0m
[0m[[0m[31merror[0m] [0m[0m            :  +- SubqueryAlias s1[0m
[0m[[0m[31merror[0m] [0m[0m            :     +- SubqueryAlias states10[0m
[0m[[0m[31merror[0m] [0m[0m            :        +- Project [_c0#42 AS stateID#118, _c1#43 AS regionID#119, _c2#44 AS state#120, _c3#45 AS totalPop#121, _c4#46 AS White#122, _c5#47 AS African#123, _c6#48 AS Indian#124, _c7#49 AS Asian#125, _c8#50 AS NativeHawaiian_PacificIslander#126, _c9#51 AS OtherRace#127, _c10#52 AS Hispanic_Latino#128][0m
[0m[[0m[31merror[0m] [0m[0m            :           +- Relation[_c0#42,_c1#43,_c2#44,_c3#45,_c4#46,_c5#47,_c6#48,_c7#49,_c8#50,_c9#51,_c10#52] csv[0m
[0m[[0m[31merror[0m] [0m[0m            +- SubqueryAlias s2[0m
[0m[[0m[31merror[0m] [0m[0m               +- SubqueryAlias states20[0m
[0m[[0m[31merror[0m] [0m[0m                  +- Project [_c0#74 AS stateID#140, _c1#75 AS regionID#141, _c2#76 AS state#142, _c3#77 AS totalPop#143, _c4#78 AS White#144, _c5#79 AS African#145, _c6#80 AS Indian#146, _c7#81 AS Asian#147, _c8#82 AS NativeHawaiian_PacificIslander#148, _c9#83 AS OtherRace#149, _c10#84 AS Hispanic_Latino#150][0m
[0m[[0m[31merror[0m] [0m[0m                     +- Relation[_c0#74,_c1#75,_c2#76,_c3#77,_c4#78,_c5#79,_c6#80,_c7#81,_c8#82,_c9#83,_c10#84] csv[0m
[0m[[0m[31merror[0m] [0m[0m[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:92)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:89)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:289)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:288)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:95)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:107)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:106)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:118)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:122)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.map(List.scala:296)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:127)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:95)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:89)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:84)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.collection.immutable.List.foreach(List.scala:392)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:84)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:92)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:74)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:642)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery$.main(SQLquery.scala:50)[0m
[0m[[0m[31merror[0m] [0m[0m	at SQLquery.main(SQLquery.scala)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.reflect.Method.invoke(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.invokeMain(Run.scala:143)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.execute$1(Run.scala:93)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run$.executeSuccess(Run.scala:186)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Run.runWithLoader(Run.scala:120)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$bgRunTask$6(Defaults.scala:1981)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.Defaults$.$anonfun$termWrapper$2(Defaults.scala:1920)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:213)[0m
[0m[[0m[31merror[0m] [0m[0m	at sbt.internal.BackgroundThreadPool$BackgroundRunnable.run(DefaultBackgroundJobService.scala:369)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.lang.Thread.run(Unknown Source)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) org.apache.spark.sql.AnalysisException: cannot resolve '`2010`' given input columns: [s0.state, s1.state, s1.regionID, s0.Hispanic_Latino, s1.African, s0.NativeHawaiian_PacificIslander, s0.stateID, s0.Asian, s1.totalPop, s0.regionID, s2.state, s2.African, s2.White, s1.stateID, s1.Hispanic_Latino, s2.OtherRace, s1.Asian, s0.OtherRace, s1.NativeHawaiian_PacificIslander, s0.totalPop, s2.stateID, s0.Indian, s0.African, s2.totalPop, s2.Hispanic_Latino, s1.White, s0.White, s1.OtherRace, s1.Indian, s2.Indian, s2.regionID, s2.NativeHawaiian_PacificIslander, s2.Asian]; line 1 pos 107;[0m
[0m[[0m[31merror[0m] [0m[0m'GlobalLimit 5[0m
[0m[[0m[31merror[0m] [0m[0m+- 'LocalLimit 5[0m
[0m[[0m[31merror[0m] [0m[0m   +- 'Sort ['diffence2 DESC NULLS LAST], true[0m
[0m[[0m[31merror[0m] [0m[0m      +- 'Project [state#98, totalPop#99 AS 2000#162, totalPop#121 AS 2010#163, (cast(totalPop#121 as double) - cast(totalPop#99 as double)) AS diffence#164, '2010, totalPop#143 AS 2020#165, (cast(totalPop#143 as double) - cast(totalPop#121 as double)) AS diffence2#166][0m
[0m[[0m[31merror[0m] [0m[0m         +- Join Inner, (stateID#140 = stateID#118)[0m
[0m[[0m[31merror[0m] [0m[0m            :- Join Inner, (stateID#118 = stateID#96)[0m
[0m[[0m[31merror[0m] [0m[0m            :  :- SubqueryAlias s0[0m
[0m[[0m[31merror[0m] [0m[0m            :  :  +- SubqueryAlias states00[0m
[0m[[0m[31merror[0m] [0m[0m            :  :     +- Project [_c0#10 AS stateID#96, _c1#11 AS regionID#97, _c2#12 AS state#98, _c3#13 AS totalPop#99, _c4#14 AS White#100, _c5#15 AS African#101, _c6#16 AS Indian#102, _c7#17 AS Asian#103, _c8#18 AS NativeHawaiian_PacificIslander#104, _c9#19 AS OtherRace#105, _c10#20 AS Hispanic_Latino#106][0m
[0m[[0m[31merror[0m] [0m[0m            :  :        +- Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14,_c5#15,_c6#16,_c7#17,_c8#18,_c9#19,_c10#20] csv[0m
[0m[[0m[31merror[0m] [0m[0m            :  +- SubqueryAlias s1[0m
[0m[[0m[31merror[0m] [0m[0m            :     +- SubqueryAlias states10[0m
[0m[[0m[31merror[0m] [0m[0m            :        +- Project [_c0#42 AS stateID#118, _c1#43 AS regionID#119, _c2#44 AS state#120, _c3#45 AS totalPop#121, _c4#46 AS White#122, _c5#47 AS African#123, _c6#48 AS Indian#124, _c7#49 AS Asian#125, _c8#50 AS NativeHawaiian_PacificIslander#126, _c9#51 AS OtherRace#127, _c10#52 AS Hispanic_Latino#128][0m
[0m[[0m[31merror[0m] [0m[0m            :           +- Relation[_c0#42,_c1#43,_c2#44,_c3#45,_c4#46,_c5#47,_c6#48,_c7#49,_c8#50,_c9#51,_c10#52] csv[0m
[0m[[0m[31merror[0m] [0m[0m            +- SubqueryAlias s2[0m
[0m[[0m[31merror[0m] [0m[0m               +- SubqueryAlias states20[0m
[0m[[0m[31merror[0m] [0m[0m                  +- Project [_c0#74 AS stateID#140, _c1#75 AS regionID#141, _c2#76 AS state#142, _c3#77 AS totalPop#143, _c4#78 AS White#144, _c5#79 AS African#145, _c6#80 AS Indian#146, _c7#81 AS Asian#147, _c8#82 AS NativeHawaiian_PacificIslander#148, _c9#83 AS OtherRace#149, _c10#84 AS Hispanic_Latino#150][0m
[0m[[0m[31merror[0m] [0m[0m                     +- Relation[_c0#74,_c1#75,_c2#76,_c3#77,_c4#78,_c5#79,_c6#80,_c7#81,_c8#82,_c9#83,_c10#84] csv[0m
